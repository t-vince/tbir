This part of the assignment is based on the annual Scalable Concept Image Annotation Challenge, organised by ImageCLEF \cite{imageclef}. The dataset (given by ImageCLEF), contains sentence descriptions aligned to actual images. In this part of the assignment, we bring our previous tests into a real-life retrieval scenario: retrieve images by their descriptions using textual queries. Each query has a corresponding image ID, which can be used to verify the correctness of the model. The goal is to match queries with image descriptions as good as possible, using precision and recall as evaluation measures.
\newline
\newline
First we implemented a simple language model to retrieve the images, this was based on a unigram implementation \cite{languagemodelsforinformationretrieval}. Afterwards we extended it with word embedding, inspired by part I of this assignment. For the final method, we chose to implement Latent Semantic Indexing (LSI) with dirichlet priors. This is a method that has been mentioned several times in class and sparked our interest.
