By consulting - a subset of the data provided by the ImageCLEF challenge through KULeuven \cite{imageclef} that defines images by 5 to 51 textual descriptions - we will train a neural network that is capable of solving analogies with word embeddings as described in Part I. Because this data is aligned to actual images, we can simulate a retrieval model that will retrieve images based on their properties through textual queries.