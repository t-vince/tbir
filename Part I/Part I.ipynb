{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-based Information Retrieval\n",
    "## Assignment Part I - Warmup\n",
    "\n",
    "*Assignment part 1 (10 points out of 100 total)*\n",
    "\n",
    ">Your task will be to run several analogy solving models with several\n",
    "different representations on the benchmarking analogy dataset and report your findings. Focus on the\n",
    "following questions:\n",
    "1. Is the choice of the analogy model important? Which representations work better with which analogy\n",
    "models?\n",
    "2. Is dimensionality of the representation important when using GloVe vectors?\n",
    "3. What is the computational complexity of the analogy models given the pre-trained vectors?\n",
    "4. What are the typical errors?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Info\n",
    "\n",
    "Information about linguistic regularities in Word Predictions:\n",
    "http://www.marekrei.com/blog/linguistic-regularities-word-representations/\n",
    "\n",
    "List of questions to ask:\n",
    "http://word2vec.googlecode.com/svn/trunk/questions-words.txt\n",
    "\n",
    "Pretrained vector sets:\n",
    "* Word2Vec: https://code.google.com/archive/p/word2vec/\n",
    "* GloVe: http://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Note: This is written using Python 3 - there may be small differences if using another version\n",
    "\n",
    "Load in required libraries, load in Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from gensim import models\n",
    "#import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logger that logs (works in jupyter 3!) in console and outputs in file\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "\n",
    "Because we need to use different analogy models and need to calculate the recall value, functions would be useful...\n",
    "[Gensims' implementation](https://github.com/piskvorky/gensim/blob/develop/gensim/models/word2vec.py)\n",
    "\n",
    "The different analogy models are explained here: http://www.marekrei.com/blog/linguistic-regularities-word-representations/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1** (addition model)\n",
    "\n",
    "a : b is c : ?  (Or, a to b is c to [...], with a, b and c are word vectors)\n",
    ">1. Compute the vector c - a + b\n",
    ">2. Find the closest vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analogy_model1(a, b, c, model): \n",
    "    result = model.most_similar(positive=[c, b], negative=[a], topn=1)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2** (Multiplication model)\n",
    "\n",
    "a : b is c : d  (Or, a to b is c to d, with a, b and c are word vectors)\n",
    ">d = argmax(cos(d',c)*cos(d',b)/(cos(d'a)+e))\n",
    ">\n",
    ">e = 0.001 to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analogy_model2(a, b, c, model):\n",
    "    result = model.most_similar_cosmul(positive=[c, b], negative=[a], topn=1)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rec@ll1**\n",
    "\n",
    "Each analogy model that we test should report its performance as a *Recall@1* metric\n",
    ">[Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Recall) in information retrieval is the fraction of the documents that are relevant to the query that are successfully retrieved.\n",
    "\n",
    ">![alt text](recall_formula.png \"Recall@1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recall_analogy_model(questions, analogy_model, model):\n",
    "    right_count = 0 \n",
    "    total_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    with open(questions, 'r') as file:\n",
    "        for line in file:\n",
    "            if line[0] != ':' :   # Ignore the lines that start with a ':', they indicate semantic/syntactic relation categories\n",
    "                total_count += 1\n",
    "                words = line.split() # Split the different words\n",
    "                try:\n",
    "                    result_text = analogy_model(words[0], words[1], words[2], model)                 \n",
    "                    if result_text[0] == words[3]:\n",
    "                        right_count += 1\n",
    "                except KeyError: # If a KeyError occurs, skip line\n",
    "                    skipped_count += 1\n",
    "                \n",
    "    # Return the recall number, the recall numberv if we ignore the skipped ones,\n",
    "    # the total right, the total count and the skipped count\n",
    "    recall = float(right_count) / float(total_count)\n",
    "    recall_ignore_skipped = float(right_count) / float(total_count - skipped_count)\n",
    "    return float('%.5f'% recall), float('%.5f'% recall_ignore_skipped), float(right_count), float(total_count), float(skipped_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Googles' pre-trained Word2Vec vector set\n",
    "# Note: This will take a lot of memory and can take a while.\n",
    "# Note II: Depending on your RAM, do not load all models at the same time\n",
    "\n",
    "w2v_model = models.Word2Vec.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "w2v_model.init_sims(replace=True) # Normalize; Trims unneeded model memory = use (much) less RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec - addition model: 0.78142\n",
      "Word2Vec - addition model: 0.73588 (if run from terminal instead of notebookD: ) \n"
     ]
    }
   ],
   "source": [
    "# Run for analogy models\n",
    "print \"Word2Vec - addition model: \", recall_analogy_model('data/questions-words-test.txt', analogy_model1, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec - addition multiplication: 0.75148 (ran from terminal) \n"
     ]
    }
   ],
   "source": [
    "print (\"Word2Vec - multiplication model: \", recall_analogy_model('data/questions-words.txt', analogy_model2, w2v_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe\n",
    "\n",
    "Gloves' vector model is constructed differently than Word2Vec. But, once constructed, the vector model format is very similar to the Word2Vec model. However, there are some small differences. The answer to adapt Glove to Word2Vec is found [here](https://groups.google.com/forum/#!topic/gensim/0_SeYGVAL78) and the code [here](https://github.com/manasRK/glove-gensim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import smart_open\n",
    "import os.path\n",
    "\n",
    "def glove2word2vec(glove_filename):\n",
    "    def get_info(glove_filename): \n",
    "        num_lines = sum(1 for line in smart_open.smart_open(glove_filename))\n",
    "        dims = glove_filename.split('.')[2].split('d')[0] # file name contains the number of dimensions\n",
    "        return num_lines, dims\n",
    "    \n",
    "    def prepend_info(infile, outfile, line): # Function to prepend lines using smart_open\n",
    "        with open(infile, 'r', encoding=\"utf8\") as original: data = original.read()\n",
    "        with open(outfile, 'w', encoding=\"utf8\") as modified: modified.write(line + '\\n' + data)\n",
    "        return outfile\n",
    "    \n",
    "    word2vec_filename = glove_filename[:-3] + \"word2vec.txt\"\n",
    "    if os.path.isfile(word2vec_filename):\n",
    "        model = models.Word2Vec.load_word2vec_format(word2vec_filename)\n",
    "    else:\n",
    "        num_lines, dims = get_info(glove_filename)\n",
    "        gensim_first_line = \"{} {}\".format(num_lines, dims)\n",
    "        model_file = prepend_info(glove_filename, word2vec_filename, gensim_first_line)\n",
    "        model = models.Word2Vec.load_word2vec_format(model_file)\n",
    "    \n",
    "    model.init_sims(replace = True)  # normalize all word vectors\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from data/glove.6B.50d.word2vec.txt\n",
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO:gensim.models.word2vec:loaded (400000, 50) matrix from data/glove.6B.50d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load GloVes' pre-trained model\n",
    "# These vectors are stored in a plain text - vector dimensionality 50, 100, 200 and 300\n",
    "# only the vectors pre-trained on Wikipedia.\n",
    "glove50d_model = glove2word2vec('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe50d - addition model:  (0.18978, 0.38708, 3709.0, 19544.0, 9962.0)\n",
      "GloVe50d - multiplication model:  (0.14506, 0.29587, 2835.0, 19544.0, 9962.0)\n"
     ]
    }
   ],
   "source": [
    "# Return the recall number, the recall numberv if we ignore the skipped ones,\n",
    "# the total right, the total count and the skipped count\n",
    "print (\"GloVe50d - addition model: \", recall_analogy_model('data/questions-words.txt', analogy_model1, glove50d_model))\n",
    "print (\"GloVe50d - multiplication model: \", recall_analogy_model('data/questions-words.txt', analogy_model2, glove50d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from data/glove.6B.100d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000, 100) matrix from data/glove.6B.100d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n",
      "INFO:gensim.models.word2vec:loading projection weights from data/glove.6B.200d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000, 200) matrix from data/glove.6B.200d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "glove100d_model = glove2word2vec('data/glove.6B.100d.txt')\n",
    "glove200d_model = glove2word2vec('data/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe100d - addition model:  (0.28382, 0.5789, 5547.0, 19544.0, 9962.0)\n",
      "GloVe100d - multiplication model:  (0.26668, 0.54394, 5212.0, 19544.0, 9962.0)\n",
      "GloVe200d - addition model:  (0.30777, 0.62774, 6015.0, 19544.0, 9962.0)\n",
      "GloVe200d - multiplication model:  (0.30531, 0.62273, 5967.0, 19544.0, 9962.0)\n"
     ]
    }
   ],
   "source": [
    "# Return the recall number, the recall numberv if we ignore the skipped ones,\n",
    "# the total right, the total count and the skipped count\n",
    "print (\"GloVe100d - addition model: \", recall_analogy_model('data/questions-words.txt', analogy_model1, glove100d_model))\n",
    "print (\"GloVe100d - multiplication model: \", recall_analogy_model('data/questions-words.txt', analogy_model2, glove100d_model))\n",
    "print (\"GloVe200d - addition model: \", recall_analogy_model('data/questions-words.txt', analogy_model1, glove200d_model))\n",
    "print (\"GloVe200d - multiplication model: \", recall_analogy_model('data/questions-words.txt', analogy_model2, glove200d_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from data/glove.6B.300d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000, 300) matrix from data/glove.6B.300d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe300d - addition model:  (0.31304, 0.63849, 6118.0, 19544.0, 9962.0)\n",
      "GloVe300d - multiplication model:  (0.32214, 0.65707, 6296.0, 19544.0, 9962.0)\n"
     ]
    }
   ],
   "source": [
    "# This takes most memory, so in a different section\n",
    "glove300d_model = glove2word2vec('data/glove.6B.300d.txt')\n",
    "\n",
    "# Return the recall number, the recall numberv if we ignore the skipped ones,\n",
    "# the total right, the total count and the skipped count\n",
    "print (\"GloVe300d - addition model: \", recall_analogy_model('data/questions-words.txt', analogy_model1, glove300d_model))\n",
    "print (\"GloVe300d - multiplication model: \", recall_analogy_model('data/questions-words.txt', analogy_model2, glove300d_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## More info on Word2Vec\n",
    "\n",
    "Also, More info on how to use gensim can be found in [this tutorial](http://rare-technologies.com/word2vec-tutorial/).\n",
    "\n",
    "Gensim accepts the bin format, but if you want the txt format.. Gensim can transform it:\n",
    "\n",
    ">model = gensim.models.Word2Vec.load_word2vec_format('path/to/GoogleNews-vectors-negative300.bin', binary=True)\n",
    ">model.save_word2vec_format('path/to/GoogleNews-vectors-negative300.txt', binary=False)\n",
    "\n",
    "Once the model is loaded, Gensim supports a lot of out-of-the-box functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192315101624)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top-most similar word\n",
    "w2v_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the word that doesnt fit in the row\n",
    "w2v_model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76640122344103145"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the similarity between two words\n",
    "w2v_model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.08137441e-02,  -7.64330178e-02,   4.67502922e-02,\n",
       "         8.05143863e-02,  -3.46916839e-02,   8.23695585e-02,\n",
       "        -5.00895977e-02,   3.15378942e-02,   7.68040493e-02,\n",
       "         1.81806684e-02,   1.39137767e-02,  -9.32223070e-03,\n",
       "         9.09033418e-03,  -6.08495846e-02,  -9.92516056e-03,\n",
       "         3.69178876e-02,  -2.41172127e-02,   7.01254383e-02,\n",
       "         6.49309605e-02,  -6.19626865e-02,  -4.15558144e-02,\n",
       "         5.67682087e-02,  -1.76820919e-04,   3.65468524e-02,\n",
       "         6.41888902e-02,   9.91356559e-04,   3.39496173e-02,\n",
       "         2.46737637e-02,   1.35427425e-02,  -2.63434183e-02,\n",
       "        -5.56551069e-02,  -4.60082218e-02,  -8.64509344e-02,\n",
       "         9.32223070e-03,  -4.73068431e-02,  -1.20957099e-01,\n",
       "        -8.38536993e-02,   4.97185625e-02,   1.39137767e-02,\n",
       "        -1.38210189e-02,  -4.30399515e-02,   7.42068142e-02,\n",
       "         3.71034071e-02,   4.82344255e-02,   2.50447989e-02,\n",
       "         2.63434183e-02,   3.89585760e-03,   6.67861328e-02,\n",
       "        -6.41888902e-02,   4.60893876e-04,  -1.13536417e-01,\n",
       "        -4.37820181e-02,   2.15199757e-02,  -6.75281957e-02,\n",
       "        -7.94012845e-02,   6.71571642e-02,   9.04395524e-03,\n",
       "        -9.79529917e-02,  -1.69748086e-02,   7.16095716e-02,\n",
       "         2.09634248e-02,   1.91082545e-02,  -4.06282283e-02,\n",
       "         7.19806030e-02,  -4.41530533e-02,   3.22799608e-02,\n",
       "        -6.53019920e-02,   9.31295455e-02,  -6.60440624e-02,\n",
       "        -3.15378956e-03,   1.73458420e-02,  -6.12206198e-03,\n",
       "         7.08675012e-02,  -2.30041109e-02,  -1.58617049e-02,\n",
       "         6.93833679e-02,   8.38536993e-02,  -4.65647727e-02,\n",
       "        -9.69326496e-03,  -1.17246762e-01,   3.46916839e-02,\n",
       "         6.08495846e-02,   6.49309605e-02,   4.54516709e-02,\n",
       "         2.68999692e-02,  -1.00642983e-02,  -1.17339520e-02,\n",
       "         1.54350162e-01,  -3.85875404e-02,   2.17054915e-02,\n",
       "        -2.75956583e-03,  -3.48771997e-02,  -5.71392439e-02,\n",
       "        -9.72109213e-02,   8.23695585e-02,  -1.38210189e-02,\n",
       "         8.53378326e-02,   3.04247923e-02,   5.93654476e-02,\n",
       "         2.00358387e-02,   5.71392439e-02,  -4.35965024e-02,\n",
       "        -3.28365155e-02,   4.52661552e-02,  -2.72710025e-02,\n",
       "         1.03889532e-01,  -6.23337217e-02,   2.77116057e-03,\n",
       "         1.60286710e-01,  -4.28544320e-02,  -5.15737347e-02,\n",
       "        -5.00895977e-02,  -5.23158014e-02,  -2.91261729e-02,\n",
       "         2.37461794e-02,   1.89227369e-02,  -7.27226734e-02,\n",
       "        -2.29113530e-02,   8.64509344e-02,   2.23548021e-02,\n",
       "        -1.23183303e-01,   2.05923896e-02,  -5.15737347e-02,\n",
       "         3.10741016e-03,  -1.99430808e-02,  -6.63803134e-04,\n",
       "        -3.72889228e-02,  -1.08991256e-02,   1.37282601e-02,\n",
       "         8.19985271e-02,   2.27258354e-02,  -1.17246762e-01,\n",
       "        -8.64509344e-02,   9.94371250e-02,   3.74744385e-02,\n",
       "        -1.92937702e-02,   6.77137123e-03,   5.00895977e-02,\n",
       "        -2.03326657e-01,  -6.90123364e-02,   5.26868366e-02,\n",
       "        -1.17988832e-01,  -3.69178876e-02,   5.00895977e-02,\n",
       "        -4.41530533e-02,   2.67144516e-02,   1.08341940e-01,\n",
       "         1.33572258e-02,  -3.85875404e-02,  -1.42848110e-02,\n",
       "         5.37999384e-02,   5.41709699e-02,  -2.16127336e-02,\n",
       "         1.00921266e-01,  -7.97723234e-02,   3.66396131e-03,\n",
       "        -2.54158322e-02,  -1.83661859e-02,  -2.31896285e-02,\n",
       "         9.31295455e-02,  -3.67323719e-02,   6.77137123e-03,\n",
       "        -4.86054607e-02,  -1.81806684e-02,  -2.75956583e-03,\n",
       "         6.82702661e-02,   1.05744703e-02,  -8.01433548e-02,\n",
       "        -5.45420051e-02,  -4.86054607e-02,   6.58585457e-03,\n",
       "        -1.36818807e-03,  -7.75461197e-02,   1.37978292e-03,\n",
       "        -4.54516709e-02,  -2.33751461e-02,   2.25403178e-02,\n",
       "        -1.22905034e-03,  -6.49309605e-02,  -1.19658485e-02,\n",
       "        -3.37640978e-02,  -1.09826081e-01,   1.30789503e-02,\n",
       "        -7.12385401e-02,   1.12052284e-01,   6.01075180e-02,\n",
       "        -4.54516709e-02,   2.89406553e-02,   2.43027303e-02,\n",
       "        -1.78096350e-02,  -2.59723831e-02,   4.61473595e-03,\n",
       "        -5.49130403e-02,   1.72530841e-02,   1.40065355e-02,\n",
       "         1.47671551e-01,   5.52840754e-02,  -9.72109213e-02,\n",
       "        -1.69748086e-02,  -5.08316644e-02,  -5.26868366e-02,\n",
       "         2.50447989e-02,   5.23158014e-02,   4.35965024e-02,\n",
       "         7.71750808e-02,  -1.81806684e-02,   6.86413003e-03,\n",
       "        -3.24654803e-02,  -9.42426473e-02,  -1.29119843e-01,\n",
       "        -1.07599879e-02,   4.00716774e-02,  -8.16274881e-02,\n",
       "        -3.32075469e-02,   2.70854849e-02,   7.12385401e-02,\n",
       "        -4.26689163e-02,   1.03889532e-01,  -1.23925373e-01,\n",
       "        -6.75281957e-02,  -1.61399804e-02,  -1.02405399e-01,\n",
       "         2.52303164e-02,  -2.61579007e-02,  -7.56909475e-02,\n",
       "        -2.67144516e-02,  -9.23874825e-02,  -1.39137767e-02,\n",
       "        -2.80130710e-02,  -6.75281957e-02,   3.48771997e-02,\n",
       "        -4.74923588e-02,  -6.27047569e-02,  -1.35798469e-01,\n",
       "        -1.08341940e-01,  -6.34468198e-02,   7.49488771e-02,\n",
       "        -5.82523458e-02,   8.81205872e-03,   7.82881826e-02,\n",
       "         6.86412975e-02,  -1.04353325e-02,  -7.30937049e-02,\n",
       "        -3.65468524e-02,  -4.05818503e-03,  -1.79951508e-02,\n",
       "         2.48592813e-02,  -4.77706362e-03,   6.77137123e-03,\n",
       "        -3.04247923e-02,  -9.86950547e-02,   3.56192701e-02,\n",
       "        -2.96827238e-02,   1.78096350e-02,  -8.44102446e-03,\n",
       "         7.09602609e-03,   1.18267108e-02,   3.98861617e-03,\n",
       "        -6.45599216e-02,   9.83240269e-03,  -1.29861915e-02,\n",
       "        -5.47275227e-03,  -2.07779072e-02,  -3.33930664e-02,\n",
       "         7.47865532e-04,   8.49668011e-02,  -5.19447662e-02,\n",
       "         6.67861328e-02,  -6.19626865e-02,   7.12385401e-02,\n",
       "         1.30789503e-02,  -2.14272160e-02,  -8.65081802e-06,\n",
       "         1.62327401e-02,   2.20765267e-02,  -4.09992635e-02,\n",
       "        -1.47486040e-02,  -1.02405399e-01,   1.27079161e-02,\n",
       "         3.72889228e-02,   2.14272160e-02,   8.49668011e-02,\n",
       "        -2.08706651e-02,   5.56551069e-02,   2.25403178e-02,\n",
       "        -8.34826604e-02,   2.43027303e-02,   6.30757911e-03,\n",
       "         1.73458420e-02,   1.23925373e-01,  -1.44703284e-01,\n",
       "         6.49309605e-02,   2.15199757e-02,  -3.97006422e-02,\n",
       "         5.26868366e-02,  -5.97364828e-02,   1.22905034e-03,\n",
       "        -1.82734262e-02,  -9.42426473e-02,  -2.35606618e-02], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the raw numpy vector of a certain word\n",
    "w2v_model['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, Gensim supports the same format as Googles' question words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'correct': [], 'incorrect': [], 'section': u'capital-common-countries'},\n",
       " {'correct': [], 'incorrect': [], 'section': u'capital-world'},\n",
       " {'correct': [(u'boy', u'girl', u'brother', u'sister'),\n",
       "   (u'boy', u'girl', u'brothers', u'sisters'),\n",
       "   (u'boy', u'girl', u'dad', u'mom'),\n",
       "   (u'boy', u'girl', u'father', u'mother'),\n",
       "   (u'boy', u'girl', u'grandfather', u'grandmother'),\n",
       "   (u'boy', u'girl', u'grandson', u'granddaughter'),\n",
       "   (u'boy', u'girl', u'groom', u'bride'),\n",
       "   (u'boy', u'girl', u'he', u'she'),\n",
       "   (u'boy', u'girl', u'his', u'her'),\n",
       "   (u'boy', u'girl', u'husband', u'wife'),\n",
       "   (u'boy', u'girl', u'king', u'queen'),\n",
       "   (u'boy', u'girl', u'man', u'woman'),\n",
       "   (u'boy', u'girl', u'nephew', u'niece'),\n",
       "   (u'boy', u'girl', u'prince', u'princess'),\n",
       "   (u'boy', u'girl', u'son', u'daughter'),\n",
       "   (u'boy', u'girl', u'sons', u'daughters'),\n",
       "   (u'boy', u'girl', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'brothers', u'sisters'),\n",
       "   (u'brother', u'sister', u'dad', u'mom'),\n",
       "   (u'brother', u'sister', u'father', u'mother'),\n",
       "   (u'brother', u'sister', u'grandfather', u'grandmother'),\n",
       "   (u'brother', u'sister', u'grandson', u'granddaughter'),\n",
       "   (u'brother', u'sister', u'groom', u'bride'),\n",
       "   (u'brother', u'sister', u'he', u'she'),\n",
       "   (u'brother', u'sister', u'his', u'her'),\n",
       "   (u'brother', u'sister', u'husband', u'wife'),\n",
       "   (u'brother', u'sister', u'king', u'queen'),\n",
       "   (u'brother', u'sister', u'man', u'woman'),\n",
       "   (u'brother', u'sister', u'nephew', u'niece'),\n",
       "   (u'brother', u'sister', u'prince', u'princess'),\n",
       "   (u'brother', u'sister', u'son', u'daughter'),\n",
       "   (u'brother', u'sister', u'sons', u'daughters'),\n",
       "   (u'brother', u'sister', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'dad', u'mom'),\n",
       "   (u'brothers', u'sisters', u'father', u'mother'),\n",
       "   (u'brothers', u'sisters', u'grandfather', u'grandmother'),\n",
       "   (u'brothers', u'sisters', u'grandson', u'granddaughter'),\n",
       "   (u'brothers', u'sisters', u'groom', u'bride'),\n",
       "   (u'brothers', u'sisters', u'he', u'she'),\n",
       "   (u'brothers', u'sisters', u'his', u'her'),\n",
       "   (u'brothers', u'sisters', u'husband', u'wife'),\n",
       "   (u'brothers', u'sisters', u'king', u'queen'),\n",
       "   (u'brothers', u'sisters', u'man', u'woman'),\n",
       "   (u'brothers', u'sisters', u'nephew', u'niece'),\n",
       "   (u'brothers', u'sisters', u'prince', u'princess'),\n",
       "   (u'brothers', u'sisters', u'son', u'daughter'),\n",
       "   (u'brothers', u'sisters', u'sons', u'daughters'),\n",
       "   (u'brothers', u'sisters', u'uncle', u'aunt'),\n",
       "   (u'brothers', u'sisters', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'father', u'mother'),\n",
       "   (u'dad', u'mom', u'grandfather', u'grandmother'),\n",
       "   (u'dad', u'mom', u'grandson', u'granddaughter'),\n",
       "   (u'dad', u'mom', u'groom', u'bride'),\n",
       "   (u'dad', u'mom', u'he', u'she'),\n",
       "   (u'dad', u'mom', u'his', u'her'),\n",
       "   (u'dad', u'mom', u'king', u'queen'),\n",
       "   (u'dad', u'mom', u'man', u'woman'),\n",
       "   (u'dad', u'mom', u'nephew', u'niece'),\n",
       "   (u'dad', u'mom', u'prince', u'princess'),\n",
       "   (u'dad', u'mom', u'son', u'daughter'),\n",
       "   (u'dad', u'mom', u'sons', u'daughters'),\n",
       "   (u'dad', u'mom', u'uncle', u'aunt'),\n",
       "   (u'dad', u'mom', u'boy', u'girl'),\n",
       "   (u'dad', u'mom', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'grandfather', u'grandmother'),\n",
       "   (u'father', u'mother', u'grandson', u'granddaughter'),\n",
       "   (u'father', u'mother', u'groom', u'bride'),\n",
       "   (u'father', u'mother', u'he', u'she'),\n",
       "   (u'father', u'mother', u'his', u'her'),\n",
       "   (u'father', u'mother', u'husband', u'wife'),\n",
       "   (u'father', u'mother', u'king', u'queen'),\n",
       "   (u'father', u'mother', u'man', u'woman'),\n",
       "   (u'father', u'mother', u'nephew', u'niece'),\n",
       "   (u'father', u'mother', u'prince', u'princess'),\n",
       "   (u'father', u'mother', u'son', u'daughter'),\n",
       "   (u'father', u'mother', u'sons', u'daughters'),\n",
       "   (u'father', u'mother', u'stepfather', u'stepmother'),\n",
       "   (u'father', u'mother', u'uncle', u'aunt'),\n",
       "   (u'father', u'mother', u'boy', u'girl'),\n",
       "   (u'father', u'mother', u'brother', u'sister'),\n",
       "   (u'father', u'mother', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'dad', u'mom')],\n",
       "  'incorrect': [(u'boy', u'girl', u'stepfather', u'stepmother'),\n",
       "   (u'brother', u'sister', u'stepfather', u'stepmother'),\n",
       "   (u'brothers', u'sisters', u'stepfather', u'stepmother'),\n",
       "   (u'dad', u'mom', u'husband', u'wife'),\n",
       "   (u'dad', u'mom', u'stepfather', u'stepmother')],\n",
       "  'section': u'family'},\n",
       " {'correct': [(u'boy', u'girl', u'brother', u'sister'),\n",
       "   (u'boy', u'girl', u'brothers', u'sisters'),\n",
       "   (u'boy', u'girl', u'dad', u'mom'),\n",
       "   (u'boy', u'girl', u'father', u'mother'),\n",
       "   (u'boy', u'girl', u'grandfather', u'grandmother'),\n",
       "   (u'boy', u'girl', u'grandson', u'granddaughter'),\n",
       "   (u'boy', u'girl', u'groom', u'bride'),\n",
       "   (u'boy', u'girl', u'he', u'she'),\n",
       "   (u'boy', u'girl', u'his', u'her'),\n",
       "   (u'boy', u'girl', u'husband', u'wife'),\n",
       "   (u'boy', u'girl', u'king', u'queen'),\n",
       "   (u'boy', u'girl', u'man', u'woman'),\n",
       "   (u'boy', u'girl', u'nephew', u'niece'),\n",
       "   (u'boy', u'girl', u'prince', u'princess'),\n",
       "   (u'boy', u'girl', u'son', u'daughter'),\n",
       "   (u'boy', u'girl', u'sons', u'daughters'),\n",
       "   (u'boy', u'girl', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'brothers', u'sisters'),\n",
       "   (u'brother', u'sister', u'dad', u'mom'),\n",
       "   (u'brother', u'sister', u'father', u'mother'),\n",
       "   (u'brother', u'sister', u'grandfather', u'grandmother'),\n",
       "   (u'brother', u'sister', u'grandson', u'granddaughter'),\n",
       "   (u'brother', u'sister', u'groom', u'bride'),\n",
       "   (u'brother', u'sister', u'he', u'she'),\n",
       "   (u'brother', u'sister', u'his', u'her'),\n",
       "   (u'brother', u'sister', u'husband', u'wife'),\n",
       "   (u'brother', u'sister', u'king', u'queen'),\n",
       "   (u'brother', u'sister', u'man', u'woman'),\n",
       "   (u'brother', u'sister', u'nephew', u'niece'),\n",
       "   (u'brother', u'sister', u'prince', u'princess'),\n",
       "   (u'brother', u'sister', u'son', u'daughter'),\n",
       "   (u'brother', u'sister', u'sons', u'daughters'),\n",
       "   (u'brother', u'sister', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'dad', u'mom'),\n",
       "   (u'brothers', u'sisters', u'father', u'mother'),\n",
       "   (u'brothers', u'sisters', u'grandfather', u'grandmother'),\n",
       "   (u'brothers', u'sisters', u'grandson', u'granddaughter'),\n",
       "   (u'brothers', u'sisters', u'groom', u'bride'),\n",
       "   (u'brothers', u'sisters', u'he', u'she'),\n",
       "   (u'brothers', u'sisters', u'his', u'her'),\n",
       "   (u'brothers', u'sisters', u'husband', u'wife'),\n",
       "   (u'brothers', u'sisters', u'king', u'queen'),\n",
       "   (u'brothers', u'sisters', u'man', u'woman'),\n",
       "   (u'brothers', u'sisters', u'nephew', u'niece'),\n",
       "   (u'brothers', u'sisters', u'prince', u'princess'),\n",
       "   (u'brothers', u'sisters', u'son', u'daughter'),\n",
       "   (u'brothers', u'sisters', u'sons', u'daughters'),\n",
       "   (u'brothers', u'sisters', u'uncle', u'aunt'),\n",
       "   (u'brothers', u'sisters', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'father', u'mother'),\n",
       "   (u'dad', u'mom', u'grandfather', u'grandmother'),\n",
       "   (u'dad', u'mom', u'grandson', u'granddaughter'),\n",
       "   (u'dad', u'mom', u'groom', u'bride'),\n",
       "   (u'dad', u'mom', u'he', u'she'),\n",
       "   (u'dad', u'mom', u'his', u'her'),\n",
       "   (u'dad', u'mom', u'king', u'queen'),\n",
       "   (u'dad', u'mom', u'man', u'woman'),\n",
       "   (u'dad', u'mom', u'nephew', u'niece'),\n",
       "   (u'dad', u'mom', u'prince', u'princess'),\n",
       "   (u'dad', u'mom', u'son', u'daughter'),\n",
       "   (u'dad', u'mom', u'sons', u'daughters'),\n",
       "   (u'dad', u'mom', u'uncle', u'aunt'),\n",
       "   (u'dad', u'mom', u'boy', u'girl'),\n",
       "   (u'dad', u'mom', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'grandfather', u'grandmother'),\n",
       "   (u'father', u'mother', u'grandson', u'granddaughter'),\n",
       "   (u'father', u'mother', u'groom', u'bride'),\n",
       "   (u'father', u'mother', u'he', u'she'),\n",
       "   (u'father', u'mother', u'his', u'her'),\n",
       "   (u'father', u'mother', u'husband', u'wife'),\n",
       "   (u'father', u'mother', u'king', u'queen'),\n",
       "   (u'father', u'mother', u'man', u'woman'),\n",
       "   (u'father', u'mother', u'nephew', u'niece'),\n",
       "   (u'father', u'mother', u'prince', u'princess'),\n",
       "   (u'father', u'mother', u'son', u'daughter'),\n",
       "   (u'father', u'mother', u'sons', u'daughters'),\n",
       "   (u'father', u'mother', u'stepfather', u'stepmother'),\n",
       "   (u'father', u'mother', u'uncle', u'aunt'),\n",
       "   (u'father', u'mother', u'boy', u'girl'),\n",
       "   (u'father', u'mother', u'brother', u'sister'),\n",
       "   (u'father', u'mother', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'dad', u'mom')],\n",
       "  'incorrect': [(u'boy', u'girl', u'stepfather', u'stepmother'),\n",
       "   (u'brother', u'sister', u'stepfather', u'stepmother'),\n",
       "   (u'brothers', u'sisters', u'stepfather', u'stepmother'),\n",
       "   (u'dad', u'mom', u'husband', u'wife'),\n",
       "   (u'dad', u'mom', u'stepfather', u'stepmother')],\n",
       "  'section': 'total'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gensim supports the same evaluation set as Google does\n",
    "w2v_model.accuracy('data/questions-words-test.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
