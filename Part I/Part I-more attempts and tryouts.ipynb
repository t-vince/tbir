{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-based Information Retrieval\n",
    "## Assignment Part I - Warmup\n",
    "\n",
    "*Assignment part 1 (10 points out of 100 total)*\n",
    "\n",
    ">Your task will be to run several analogy solving models with several\n",
    "different representations on the benchmarking analogy dataset and report your findings. Focus on the\n",
    "following questions:\n",
    "1. Is the choice of the analogy model important? Which representations work better with which analogy\n",
    "models?\n",
    "2. Is dimensionality of the representation important when using GloVe vectors?\n",
    "3. What is the computational complexity of the analogy models given the pre-trained vectors?\n",
    "4. What are the typical errors?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Info\n",
    "\n",
    "Information about linguistic regularities in Word Predictions:\n",
    "http://www.marekrei.com/blog/linguistic-regularities-word-representations/\n",
    "\n",
    "List of questions to ask:\n",
    "http://word2vec.googlecode.com/svn/trunk/questions-words.txt\n",
    "\n",
    "Pretrained vector sets:\n",
    "* Word2Vec: https://code.google.com/archive/p/word2vec/\n",
    "* GloVe: http://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Note: This is written using Python 3 - there may be small differences if using another version\n",
    "\n",
    "Load in required libraries, load in Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from gensim import models\n",
    "#import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logger that logs (works in jupyter 3!) in console and outputs in file\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "\n",
    "Because we need to use different analogy models and need to calculate the recall value, functions would be useful...\n",
    "[Gensims' implementation](https://github.com/piskvorky/gensim/blob/develop/gensim/models/word2vec.py)\n",
    "\n",
    "The different analogy models are explained here: http://www.marekrei.com/blog/linguistic-regularities-word-representations/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1** (addition model)\n",
    "\n",
    "a : b is c : ?  (Or, a to b is c to [...], with a, b and c are word vectors)\n",
    ">1. Compute the vector c - a + b\n",
    ">2. Find the closest vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analogy_model1(a, b, c, model): \n",
    "    result = model.most_similar(positive=[c, b], negative=[a], topn=1)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2** (Multiplication model)\n",
    "\n",
    "a : b is c : d  (Or, a to b is c to d, with a, b and c are word vectors)\n",
    ">d = argmax(cos(d',c)*cos(d',b)/(cos(d'a)+e))\n",
    ">\n",
    ">e = 0.001 to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analogy_model2(a, b, c, model):\n",
    "    result = model.most_similar_cosmul(positive=[c, b], negative=[a], topn=1)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rec@ll1**\n",
    "\n",
    "Each analogy model that we test should report its performance as a *Recall@1* metric\n",
    ">[Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Recall) in information retrieval is the fraction of the documents that are relevant to the query that are successfully retrieved.\n",
    "\n",
    ">![alt text](recall_formula.png \"Recall@1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_analogy_model(questions, analogy_model, model):\n",
    "    right_count = 0 \n",
    "    total_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    with open(questions, 'r') as file:\n",
    "        for line in file:\n",
    "            if line[0] != ':' :   # Ignore the lines that start with a ':', they indicate semantic/syntactic relation categories\n",
    "                total_count += 1\n",
    "                words = line.split() # Split the different words\n",
    "                try:\n",
    "                    result_text = analogy_model(words[0], words[1], words[2], model)                 \n",
    "                    if result_text[0] == words[3]:\n",
    "                        right_count += 1\n",
    "                except KeyError, e:\n",
    "                    skipped_count += 1\n",
    "                \n",
    "    # Return the recall number, the total right, the total count and the skipped count\n",
    "    # The recall number is calculated based on\n",
    "    recall = float(right_count) / float(total_count)\n",
    "    recall_ignore_skipped = float(right_count) / float(total_count - skipped_count)\n",
    "    return float('%.5f'% recall), float('%.5f'% recall_ignore_skipped), float(right_count), float(total_count), float(skipped_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    self.log_accuracy(total)\\n    sections.append(total)\\n    return sections\\n    \\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from numpy import exp, log, dot, zeros, outer, random, dtype, float32 as REAL,\\\n",
    "    uint32, seterr, array, uint8, vstack, fromstring, sqrt, newaxis,\\\n",
    "    ndarray, empty, sum as np_sum, prod, ones, ascontiguousarray\n",
    "\n",
    "from gensim import utils, matutils  # utility fnc for pickling, common scipy operations etc\n",
    "from six import iteritems, itervalues\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Modified gensim accuracy for recall analogy\n",
    "def recall_gensim_model(questions, analogy_model, model):\n",
    "    #def accuracy(self, questions, restrict_vocab=30000, most_similar=most_similar):\n",
    "    \"\"\"\n",
    "    Compute accuracy of the model. `questions` is a filename where lines are\n",
    "    4-tuples of words, split into sections by \": SECTION NAME\" lines.\n",
    "    See https://code.google.com/p/word2vec/source/browse/trunk/questions-words.txt for an example.\n",
    "    The accuracy is reported (=printed to log and returned as a list) for each\n",
    "    section separately, plus there's one aggregate summary at the end.\n",
    "    Use `restrict_vocab` to ignore all questions containing a word whose frequency\n",
    "    is not in the top-N most frequent words (default top 30,000).\n",
    "    This method corresponds to the `compute-accuracy` script of the original C word2vec.\n",
    "    \"\"\"\n",
    "    restrict_vocab = 30000\n",
    "    ok_vocab = dict(sorted(iteritems(model.vocab),\n",
    "                           key=lambda item: -item[1].count)[:restrict_vocab])\n",
    "    ok_index = set(v.index for v in itervalues(ok_vocab))\n",
    "\n",
    "    sections, section = [], None\n",
    "    for line_no, line in enumerate(utils.smart_open(questions)):\n",
    "        # TODO: use level3 BLAS (=evaluate multiple questions at once), for speed\n",
    "        line = utils.to_unicode(line)\n",
    "        if line.startswith(': '):\n",
    "            # a new section starts => store the old section\n",
    "            if section:\n",
    "                sections.append(section)\n",
    "                #self.log_accuracy(section)\n",
    "            section = {'section': line.lstrip(': ').strip(), 'correct': [], 'incorrect': []}\n",
    "        else:\n",
    "            if not section:\n",
    "                raise ValueError(\"missing section header before line #%i in %s\" % (line_no, questions))\n",
    "            try:\n",
    "                a, b, c, expected = [word.lower() for word in line.split()]  # TODO assumes vocabulary preprocessing uses lowercase, too...\n",
    "            except:\n",
    "                logger.info(\"skipping invalid line #%i in %s\" % (line_no, questions))\n",
    "            if a not in ok_vocab or b not in ok_vocab or c not in ok_vocab or expected not in ok_vocab:\n",
    "                logger.debug(\"skipping line #%i with OOV words: %s\" % (line_no, line.strip()))\n",
    "                continue\n",
    "\n",
    "            ignore = set(model.vocab[v].index for v in [a, b, c])  # indexes of words to ignore\n",
    "            predicted = None\n",
    "            # find the most likely prediction, ignoring OOV words and input words\n",
    "            #sims = analogy_model(a, b, c, model)\n",
    "            sims = model.most_similar(positive=[b, c], negative=[a], topn=False)\n",
    "            for index in matutils.argsort(sims, reverse= True):\n",
    "                if index in ok_index and index not in ignore:\n",
    "                    predicted = model.index2word[index]\n",
    "                    #if predicted != expected:\n",
    "                    #    logger.debug(\"%s: expected %s, predicted %s\", line.strip(), expected, predicted)\n",
    "                    #break\n",
    "            if predicted == expected:\n",
    "                section['correct'].append((a, b, c, expected))\n",
    "            else:\n",
    "                section['incorrect'].append((a, b, c, expected))\n",
    "    if section:\n",
    "        # store the last section, too\n",
    "        sections.append(section)\n",
    "        #self.log_accuracy(section)\n",
    "    '''\n",
    "    total = {\n",
    "        'section': 'total',\n",
    "        'correct': sum((s['correct'] for s in sections), []),\n",
    "        'incorrect': sum((s['incorrect'] for s in sections), []),\n",
    "    }\n",
    "    '''\n",
    "    print sections\n",
    "    correct = sum(len(s['correct']) for s in sections)\n",
    "    print \"Correct: \", correct\n",
    "    total = correct + sum(len(s['incorrect']) for s in sections)\n",
    "    print \"Total: \", total\n",
    "    \n",
    "    recall = float(correct) / float(total)\n",
    "    return float('%.5f'% recall)\n",
    "'''\n",
    "    self.log_accuracy(total)\n",
    "    sections.append(total)\n",
    "    return sections\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def recallOfAnalogyModel(questions, r_model, a_model):\n",
    "    \"\"\"\n",
    "    questions are file path for the test file. In this case, 'questions-words.txt'\n",
    "    r_model is representation model of word vector (word2vec, GloVe)\n",
    "    a_model is analogy model (1, 2). 1 stands for findAnalogy_model1, 2 stands for findAnalogy_model2\n",
    "    \"\"\"\n",
    "    count_correct = 0 # counter for number of correct result\n",
    "    count_total = 0 # count total number of questions\n",
    "    \n",
    "    if a_model == 1:\n",
    "        with open(questions, 'r') as ifile:\n",
    "            for line in ifile:\n",
    "                if line[0] != ':' :\n",
    "                    count_total += 1\n",
    "                    line_sp = line.split()\n",
    "                    result_text = analogy_model1(line_sp[0], line_sp[1], line_sp[2], r_model)                 \n",
    "                    if result_text[0] == line_sp[3]:\n",
    "                        count_correct += 1\n",
    "    elif a_model == 2:\n",
    "        with open(questions, 'r') as ifile:\n",
    "            for line in ifile:\n",
    "                if line[0] != ':' :\n",
    "                    count_total += 1\n",
    "                    line_sp = line.split()\n",
    "                    result_text = analogy_model2(line_sp[0], line_sp[1], line_sp[2], r_model)\n",
    "                    if result_text[0] == line_sp[3]:\n",
    "                        count_correct += 1\n",
    "    else:\n",
    "        raise ValueError(\"invalid analogy model\")\n",
    "    recall = float(count_correct) / float(count_total)\n",
    "    return float('%.4f'% recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec - addition model"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-16a07c5caad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Word2Vec - addition model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecallOfAnalogyModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/questions-words.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-8cb0c4aca676>\u001b[0m in \u001b[0;36mrecallOfAnalogyModel\u001b[1;34m(questions, r_model, a_model)\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mcount_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mline_sp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mresult_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalogy_model1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_sp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_sp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_sp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mresult_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mline_sp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                         \u001b[0mcount_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-8822d8738962>\u001b[0m in \u001b[0;36manalogy_model1\u001b[1;34m(a, b, c, model)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# ignore words from the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_words\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print \"Word2Vec - addition model\", recallOfAnalogyModel('data/questions-words.txt', w2v_model, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Googles' pre-trained Word2Vec vector set\n",
    "# Note: This will take a lot of memory and can take a while.\n",
    "# Note II: Depending on your RAM, do not load all models at the same time\n",
    "\n",
    "w2v_model = models.Word2Vec.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "w2v_model.init_sims(replace=True) # Trim unneeded model memory = use (much) less RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec - addition model 0.78142\n"
     ]
    }
   ],
   "source": [
    "# Run for analogy models\n",
    "print \"Word2Vec - addition model\", recall_analogy_model('data/questions-words-test.txt', analogy_model1, w2v_model)\n",
    "#print (\"Word2Vec - multiplication model\", recall_analogy_model('data/questions-words.txt', analogy_model2, w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Word2Vec - addition model\", recall_analogy_model('data/questions-words.txt', analogy_model1, w2v_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'sisters', 0.8290482759475708)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_model1('father', 'mother', 'brothers', w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'incorrect': [], 'section': u'capital-common-countries', 'correct': [(u'boy', u'girl', u'brother', u'sister'), (u'boy', u'girl', u'brothers', u'sisters'), (u'boy', u'girl', u'dad', u'mom'), (u'boy', u'girl', u'father', u'mother')]}, {'incorrect': [1, 2, 3], 'section': u'capital-world', 'correct': [1, 2, 3, 4, 5, 6]}]\n",
      "Correct:    10\n",
      "Incorrect:  3\n",
      "Total:      13\n",
      "Procent:    0.769230769231\n"
     ]
    }
   ],
   "source": [
    "somevar = [{'correct': [(u'boy', u'girl', u'brother', u'sister'),\n",
    "   (u'boy', u'girl', u'brothers', u'sisters'),\n",
    "   (u'boy', u'girl', u'dad', u'mom'),\n",
    "   (u'boy', u'girl', u'father', u'mother')], 'incorrect': [], 'section': u'capital-common-countries'},\n",
    " {'correct': [1,2,3,4,5,6], 'incorrect': [1,2,3], 'section': u'capital-world'}]\n",
    "\n",
    "print somevar\n",
    "\n",
    "correct = sum(len(s['correct']) for s in somevar)\n",
    "incorrect = sum(len(s['incorrect']) for s in somevar)\n",
    "total = correct + incorrect\n",
    "print \"Correct:   \", correct\n",
    "print \"Incorrect: \", incorrect\n",
    "print \"Total:     \", total\n",
    "print \"Procent:   \", (float(correct) / float(total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe\n",
    "\n",
    "Gloves' vector model is constructed differently than Word2Vec. But, once constructed, the vector model format is very similar to the Word2Vec model. However, there are some small differences. The answer to adapt Glove to Word2Vec is found [here](https://groups.google.com/forum/#!topic/gensim/0_SeYGVAL78) and the code [here](https://github.com/manasRK/glove-gensim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smart_open\n",
    "import os.path\n",
    "\n",
    "def glove2word2vec(glove_filename):\n",
    "    def get_info(glove_filename): \n",
    "        num_lines = sum(1 for line in smart_open.smart_open(glove_filename))\n",
    "        dims = glove_filename.split('.')[2].split('d')[0] # file name contains the number of dimensions\n",
    "        return num_lines, dims\n",
    "    \n",
    "    def prepend_info(infile, outfile, line): # Function to prepend lines using smart_open\n",
    "        with open(infile, 'r', encoding=\"utf8\") as original: data = original.read()\n",
    "        with open(outfile, 'w', encoding=\"utf8\") as modified: modified.write(line + '\\n' + data)\n",
    "        return outfile\n",
    "    \n",
    "    word2vec_filename = glove_filename[:-3] + \"word2vec.txt\"\n",
    "    if os.path.isfile(word2vec_filename):\n",
    "        model = models.Word2Vec.load_word2vec_format(word2vec_filename)\n",
    "    else:\n",
    "        num_lines, dims = get_info(glove_filename)\n",
    "        gensim_first_line = \"{} {}\".format(num_lines, dims)\n",
    "        model_file = prepend_info(glove_filename, word2vec_filename, gensim_first_line)\n",
    "        model = models.Word2Vec.load_word2vec_format(model_file)\n",
    "    \n",
    "    model.init_sims(replace = True)  # normalize all word vectors\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from data/glove.6B.50d.word2vec.txt\n",
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO:gensim.models.word2vec:loaded (400000, 50) matrix from data/glove.6B.50d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load GloVes' pre-trained model\n",
    "# These vectors are stored in a plain text - vector dimensionality 50, 100, 200 and 300\n",
    "# only the vectors pre-trained on Wikipedia.\n",
    "glove50d_model = glove2word2vec('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'Baghdad' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-631ac8cc2cd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"GloVe50d - addition model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_analogy_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'questions-words.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalogy_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglove50d_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#print \"GloVe50d - multiplication model\", recall_analogy_model('questions-words.txt', analogy_model2, glove50d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-18c25c8d73c4>\u001b[0m in \u001b[0;36mrecall_analogy_model\u001b[1;34m(questions, analogy_model, model)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mtotal_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Split the different words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mresult_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalogy_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mright_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-46cbf59c42c5>\u001b[0m in \u001b[0;36manalogy_model1\u001b[1;34m(a, b, c, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0manalogy_model1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'Baghdad' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "print (\"GloVe50d - addition model\", recall_analogy_model('data/questions-words.txt', analogy_model1, glove50d_model))\n",
    "print (\"GloVe50d - multiplication model\", recall_analogy_model('data/questions-words.txt', analogy_model2, glove50d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from data/glove.6B.100d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000, 100) matrix from data/glove.6B.100d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n",
      "INFO:gensim.models.word2vec:loading projection weights from data/glove.6B.200d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000, 200) matrix from data/glove.6B.200d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d63328ef8487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mglove100d_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglove2word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/glove.6B.100d.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mglove200d_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglove2word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/glove.6B.200d.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mglove300d_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglove2word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/glove.6B.300d.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-83c5b369aa9f>\u001b[0m in \u001b[0;36mglove2word2vec\u001b[1;34m(glove_filename)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mnum_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mgensim_first_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{} {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mmodel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepend_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vec_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgensim_first_line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-83c5b369aa9f>\u001b[0m in \u001b[0;36mprepend_info\u001b[1;34m(infile, outfile, line)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprepend_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Function to prepend lines using smart_open\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodified\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "glove100d_model = glove2word2vec('data/glove.6B.100d.txt')\n",
    "glove200d_model = glove2word2vec('data/glove.6B.200d.txt')\n",
    "glove300d_model = glove2word2vec('data/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'Baghdad' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ce679e654a72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"GloVe100d - addition model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_analogy_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'questions-words.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalogy_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglove100d_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#print (\"GloVe100d - multiplication model\", recall_analogy_model('questions-words.txt', analogy_model2, glove100d_model))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print (\"GloVe200d - addition model\", recall_analogy_model('questions-words.txt', analogy_model1, glove200d_model))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print (\"GloVe200d - multiplication model\", recall_analogy_model('questions-words.txt', analogy_model2, glove200d_model))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print (\"GloVe300d - addition model\", recall_analogy_model('questions-words.txt', analogy_model1, glove300d_model))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-18c25c8d73c4>\u001b[0m in \u001b[0;36mrecall_analogy_model\u001b[1;34m(questions, analogy_model, model)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mtotal_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Split the different words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mresult_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalogy_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mright_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-46cbf59c42c5>\u001b[0m in \u001b[0;36manalogy_model1\u001b[1;34m(a, b, c, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0manalogy_model1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'Baghdad' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "print (\"GloVe100d - addition model\", recall_analogy_model('data/questions-words.txt', analogy_model1, glove100d_model))\n",
    "#print (\"GloVe100d - multiplication model\", recall_analogy_model('data/questions-words.txt', analogy_model2, glove100d_model))\n",
    "#print (\"GloVe200d - addition model\", recall_analogy_model('data/questions-words.txt', analogy_model1, glove200d_model))\n",
    "#print (\"GloVe200d - multiplication model\", recall_analogy_model('data/questions-words.txt', analogy_model2, glove200d_model))\n",
    "#print (\"GloVe300d - addition model\", recall_analogy_model('data/questions-words.txt', analogy_model1, glove300d_model))\n",
    "#print (\"GloVe300d - multiplication model\", recall_analogy_model('data/questions-words.txt', analogy_model2, glove300d_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## More info on Word2Vec\n",
    "\n",
    "Also, More info on how to use gensim can be found in [this tutorial](http://rare-technologies.com/word2vec-tutorial/).\n",
    "\n",
    "Gensim accepts the bin format, but if you want the txt format.. Gensim can transform it:\n",
    "\n",
    ">model = gensim.models.Word2Vec.load_word2vec_format('path/to/GoogleNews-vectors-negative300.bin', binary=True)\n",
    ">model.save_word2vec_format('path/to/GoogleNews-vectors-negative300.txt', binary=False)\n",
    "\n",
    "Once the model is loaded, Gensim supports a lot of out-of-the-box functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192315101624)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top-most similar word\n",
    "w2v_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the word that doesnt fit in the row\n",
    "w2v_model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76640122344103145"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the similarity between two words\n",
    "w2v_model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.08137441e-02,  -7.64330178e-02,   4.67502922e-02,\n",
       "         8.05143863e-02,  -3.46916839e-02,   8.23695585e-02,\n",
       "        -5.00895977e-02,   3.15378942e-02,   7.68040493e-02,\n",
       "         1.81806684e-02,   1.39137767e-02,  -9.32223070e-03,\n",
       "         9.09033418e-03,  -6.08495846e-02,  -9.92516056e-03,\n",
       "         3.69178876e-02,  -2.41172127e-02,   7.01254383e-02,\n",
       "         6.49309605e-02,  -6.19626865e-02,  -4.15558144e-02,\n",
       "         5.67682087e-02,  -1.76820919e-04,   3.65468524e-02,\n",
       "         6.41888902e-02,   9.91356559e-04,   3.39496173e-02,\n",
       "         2.46737637e-02,   1.35427425e-02,  -2.63434183e-02,\n",
       "        -5.56551069e-02,  -4.60082218e-02,  -8.64509344e-02,\n",
       "         9.32223070e-03,  -4.73068431e-02,  -1.20957099e-01,\n",
       "        -8.38536993e-02,   4.97185625e-02,   1.39137767e-02,\n",
       "        -1.38210189e-02,  -4.30399515e-02,   7.42068142e-02,\n",
       "         3.71034071e-02,   4.82344255e-02,   2.50447989e-02,\n",
       "         2.63434183e-02,   3.89585760e-03,   6.67861328e-02,\n",
       "        -6.41888902e-02,   4.60893876e-04,  -1.13536417e-01,\n",
       "        -4.37820181e-02,   2.15199757e-02,  -6.75281957e-02,\n",
       "        -7.94012845e-02,   6.71571642e-02,   9.04395524e-03,\n",
       "        -9.79529917e-02,  -1.69748086e-02,   7.16095716e-02,\n",
       "         2.09634248e-02,   1.91082545e-02,  -4.06282283e-02,\n",
       "         7.19806030e-02,  -4.41530533e-02,   3.22799608e-02,\n",
       "        -6.53019920e-02,   9.31295455e-02,  -6.60440624e-02,\n",
       "        -3.15378956e-03,   1.73458420e-02,  -6.12206198e-03,\n",
       "         7.08675012e-02,  -2.30041109e-02,  -1.58617049e-02,\n",
       "         6.93833679e-02,   8.38536993e-02,  -4.65647727e-02,\n",
       "        -9.69326496e-03,  -1.17246762e-01,   3.46916839e-02,\n",
       "         6.08495846e-02,   6.49309605e-02,   4.54516709e-02,\n",
       "         2.68999692e-02,  -1.00642983e-02,  -1.17339520e-02,\n",
       "         1.54350162e-01,  -3.85875404e-02,   2.17054915e-02,\n",
       "        -2.75956583e-03,  -3.48771997e-02,  -5.71392439e-02,\n",
       "        -9.72109213e-02,   8.23695585e-02,  -1.38210189e-02,\n",
       "         8.53378326e-02,   3.04247923e-02,   5.93654476e-02,\n",
       "         2.00358387e-02,   5.71392439e-02,  -4.35965024e-02,\n",
       "        -3.28365155e-02,   4.52661552e-02,  -2.72710025e-02,\n",
       "         1.03889532e-01,  -6.23337217e-02,   2.77116057e-03,\n",
       "         1.60286710e-01,  -4.28544320e-02,  -5.15737347e-02,\n",
       "        -5.00895977e-02,  -5.23158014e-02,  -2.91261729e-02,\n",
       "         2.37461794e-02,   1.89227369e-02,  -7.27226734e-02,\n",
       "        -2.29113530e-02,   8.64509344e-02,   2.23548021e-02,\n",
       "        -1.23183303e-01,   2.05923896e-02,  -5.15737347e-02,\n",
       "         3.10741016e-03,  -1.99430808e-02,  -6.63803134e-04,\n",
       "        -3.72889228e-02,  -1.08991256e-02,   1.37282601e-02,\n",
       "         8.19985271e-02,   2.27258354e-02,  -1.17246762e-01,\n",
       "        -8.64509344e-02,   9.94371250e-02,   3.74744385e-02,\n",
       "        -1.92937702e-02,   6.77137123e-03,   5.00895977e-02,\n",
       "        -2.03326657e-01,  -6.90123364e-02,   5.26868366e-02,\n",
       "        -1.17988832e-01,  -3.69178876e-02,   5.00895977e-02,\n",
       "        -4.41530533e-02,   2.67144516e-02,   1.08341940e-01,\n",
       "         1.33572258e-02,  -3.85875404e-02,  -1.42848110e-02,\n",
       "         5.37999384e-02,   5.41709699e-02,  -2.16127336e-02,\n",
       "         1.00921266e-01,  -7.97723234e-02,   3.66396131e-03,\n",
       "        -2.54158322e-02,  -1.83661859e-02,  -2.31896285e-02,\n",
       "         9.31295455e-02,  -3.67323719e-02,   6.77137123e-03,\n",
       "        -4.86054607e-02,  -1.81806684e-02,  -2.75956583e-03,\n",
       "         6.82702661e-02,   1.05744703e-02,  -8.01433548e-02,\n",
       "        -5.45420051e-02,  -4.86054607e-02,   6.58585457e-03,\n",
       "        -1.36818807e-03,  -7.75461197e-02,   1.37978292e-03,\n",
       "        -4.54516709e-02,  -2.33751461e-02,   2.25403178e-02,\n",
       "        -1.22905034e-03,  -6.49309605e-02,  -1.19658485e-02,\n",
       "        -3.37640978e-02,  -1.09826081e-01,   1.30789503e-02,\n",
       "        -7.12385401e-02,   1.12052284e-01,   6.01075180e-02,\n",
       "        -4.54516709e-02,   2.89406553e-02,   2.43027303e-02,\n",
       "        -1.78096350e-02,  -2.59723831e-02,   4.61473595e-03,\n",
       "        -5.49130403e-02,   1.72530841e-02,   1.40065355e-02,\n",
       "         1.47671551e-01,   5.52840754e-02,  -9.72109213e-02,\n",
       "        -1.69748086e-02,  -5.08316644e-02,  -5.26868366e-02,\n",
       "         2.50447989e-02,   5.23158014e-02,   4.35965024e-02,\n",
       "         7.71750808e-02,  -1.81806684e-02,   6.86413003e-03,\n",
       "        -3.24654803e-02,  -9.42426473e-02,  -1.29119843e-01,\n",
       "        -1.07599879e-02,   4.00716774e-02,  -8.16274881e-02,\n",
       "        -3.32075469e-02,   2.70854849e-02,   7.12385401e-02,\n",
       "        -4.26689163e-02,   1.03889532e-01,  -1.23925373e-01,\n",
       "        -6.75281957e-02,  -1.61399804e-02,  -1.02405399e-01,\n",
       "         2.52303164e-02,  -2.61579007e-02,  -7.56909475e-02,\n",
       "        -2.67144516e-02,  -9.23874825e-02,  -1.39137767e-02,\n",
       "        -2.80130710e-02,  -6.75281957e-02,   3.48771997e-02,\n",
       "        -4.74923588e-02,  -6.27047569e-02,  -1.35798469e-01,\n",
       "        -1.08341940e-01,  -6.34468198e-02,   7.49488771e-02,\n",
       "        -5.82523458e-02,   8.81205872e-03,   7.82881826e-02,\n",
       "         6.86412975e-02,  -1.04353325e-02,  -7.30937049e-02,\n",
       "        -3.65468524e-02,  -4.05818503e-03,  -1.79951508e-02,\n",
       "         2.48592813e-02,  -4.77706362e-03,   6.77137123e-03,\n",
       "        -3.04247923e-02,  -9.86950547e-02,   3.56192701e-02,\n",
       "        -2.96827238e-02,   1.78096350e-02,  -8.44102446e-03,\n",
       "         7.09602609e-03,   1.18267108e-02,   3.98861617e-03,\n",
       "        -6.45599216e-02,   9.83240269e-03,  -1.29861915e-02,\n",
       "        -5.47275227e-03,  -2.07779072e-02,  -3.33930664e-02,\n",
       "         7.47865532e-04,   8.49668011e-02,  -5.19447662e-02,\n",
       "         6.67861328e-02,  -6.19626865e-02,   7.12385401e-02,\n",
       "         1.30789503e-02,  -2.14272160e-02,  -8.65081802e-06,\n",
       "         1.62327401e-02,   2.20765267e-02,  -4.09992635e-02,\n",
       "        -1.47486040e-02,  -1.02405399e-01,   1.27079161e-02,\n",
       "         3.72889228e-02,   2.14272160e-02,   8.49668011e-02,\n",
       "        -2.08706651e-02,   5.56551069e-02,   2.25403178e-02,\n",
       "        -8.34826604e-02,   2.43027303e-02,   6.30757911e-03,\n",
       "         1.73458420e-02,   1.23925373e-01,  -1.44703284e-01,\n",
       "         6.49309605e-02,   2.15199757e-02,  -3.97006422e-02,\n",
       "         5.26868366e-02,  -5.97364828e-02,   1.22905034e-03,\n",
       "        -1.82734262e-02,  -9.42426473e-02,  -2.35606618e-02], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the raw numpy vector of a certain word\n",
    "w2v_model['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, Gensim supports the same format as Googles' question words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'correct': [], 'incorrect': [], 'section': u'capital-common-countries'},\n",
       " {'correct': [], 'incorrect': [], 'section': u'capital-world'},\n",
       " {'correct': [(u'boy', u'girl', u'brother', u'sister'),\n",
       "   (u'boy', u'girl', u'brothers', u'sisters'),\n",
       "   (u'boy', u'girl', u'dad', u'mom'),\n",
       "   (u'boy', u'girl', u'father', u'mother'),\n",
       "   (u'boy', u'girl', u'grandfather', u'grandmother'),\n",
       "   (u'boy', u'girl', u'grandson', u'granddaughter'),\n",
       "   (u'boy', u'girl', u'groom', u'bride'),\n",
       "   (u'boy', u'girl', u'he', u'she'),\n",
       "   (u'boy', u'girl', u'his', u'her'),\n",
       "   (u'boy', u'girl', u'husband', u'wife'),\n",
       "   (u'boy', u'girl', u'king', u'queen'),\n",
       "   (u'boy', u'girl', u'man', u'woman'),\n",
       "   (u'boy', u'girl', u'nephew', u'niece'),\n",
       "   (u'boy', u'girl', u'prince', u'princess'),\n",
       "   (u'boy', u'girl', u'son', u'daughter'),\n",
       "   (u'boy', u'girl', u'sons', u'daughters'),\n",
       "   (u'boy', u'girl', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'brothers', u'sisters'),\n",
       "   (u'brother', u'sister', u'dad', u'mom'),\n",
       "   (u'brother', u'sister', u'father', u'mother'),\n",
       "   (u'brother', u'sister', u'grandfather', u'grandmother'),\n",
       "   (u'brother', u'sister', u'grandson', u'granddaughter'),\n",
       "   (u'brother', u'sister', u'groom', u'bride'),\n",
       "   (u'brother', u'sister', u'he', u'she'),\n",
       "   (u'brother', u'sister', u'his', u'her'),\n",
       "   (u'brother', u'sister', u'husband', u'wife'),\n",
       "   (u'brother', u'sister', u'king', u'queen'),\n",
       "   (u'brother', u'sister', u'man', u'woman'),\n",
       "   (u'brother', u'sister', u'nephew', u'niece'),\n",
       "   (u'brother', u'sister', u'prince', u'princess'),\n",
       "   (u'brother', u'sister', u'son', u'daughter'),\n",
       "   (u'brother', u'sister', u'sons', u'daughters'),\n",
       "   (u'brother', u'sister', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'dad', u'mom'),\n",
       "   (u'brothers', u'sisters', u'father', u'mother'),\n",
       "   (u'brothers', u'sisters', u'grandfather', u'grandmother'),\n",
       "   (u'brothers', u'sisters', u'grandson', u'granddaughter'),\n",
       "   (u'brothers', u'sisters', u'groom', u'bride'),\n",
       "   (u'brothers', u'sisters', u'he', u'she'),\n",
       "   (u'brothers', u'sisters', u'his', u'her'),\n",
       "   (u'brothers', u'sisters', u'husband', u'wife'),\n",
       "   (u'brothers', u'sisters', u'king', u'queen'),\n",
       "   (u'brothers', u'sisters', u'man', u'woman'),\n",
       "   (u'brothers', u'sisters', u'nephew', u'niece'),\n",
       "   (u'brothers', u'sisters', u'prince', u'princess'),\n",
       "   (u'brothers', u'sisters', u'son', u'daughter'),\n",
       "   (u'brothers', u'sisters', u'sons', u'daughters'),\n",
       "   (u'brothers', u'sisters', u'uncle', u'aunt'),\n",
       "   (u'brothers', u'sisters', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'father', u'mother'),\n",
       "   (u'dad', u'mom', u'grandfather', u'grandmother'),\n",
       "   (u'dad', u'mom', u'grandson', u'granddaughter'),\n",
       "   (u'dad', u'mom', u'groom', u'bride'),\n",
       "   (u'dad', u'mom', u'he', u'she'),\n",
       "   (u'dad', u'mom', u'his', u'her'),\n",
       "   (u'dad', u'mom', u'king', u'queen'),\n",
       "   (u'dad', u'mom', u'man', u'woman'),\n",
       "   (u'dad', u'mom', u'nephew', u'niece'),\n",
       "   (u'dad', u'mom', u'prince', u'princess'),\n",
       "   (u'dad', u'mom', u'son', u'daughter'),\n",
       "   (u'dad', u'mom', u'sons', u'daughters'),\n",
       "   (u'dad', u'mom', u'uncle', u'aunt'),\n",
       "   (u'dad', u'mom', u'boy', u'girl'),\n",
       "   (u'dad', u'mom', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'grandfather', u'grandmother'),\n",
       "   (u'father', u'mother', u'grandson', u'granddaughter'),\n",
       "   (u'father', u'mother', u'groom', u'bride'),\n",
       "   (u'father', u'mother', u'he', u'she'),\n",
       "   (u'father', u'mother', u'his', u'her'),\n",
       "   (u'father', u'mother', u'husband', u'wife'),\n",
       "   (u'father', u'mother', u'king', u'queen'),\n",
       "   (u'father', u'mother', u'man', u'woman'),\n",
       "   (u'father', u'mother', u'nephew', u'niece'),\n",
       "   (u'father', u'mother', u'prince', u'princess'),\n",
       "   (u'father', u'mother', u'son', u'daughter'),\n",
       "   (u'father', u'mother', u'sons', u'daughters'),\n",
       "   (u'father', u'mother', u'stepfather', u'stepmother'),\n",
       "   (u'father', u'mother', u'uncle', u'aunt'),\n",
       "   (u'father', u'mother', u'boy', u'girl'),\n",
       "   (u'father', u'mother', u'brother', u'sister'),\n",
       "   (u'father', u'mother', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'dad', u'mom')],\n",
       "  'incorrect': [(u'boy', u'girl', u'stepfather', u'stepmother'),\n",
       "   (u'brother', u'sister', u'stepfather', u'stepmother'),\n",
       "   (u'brothers', u'sisters', u'stepfather', u'stepmother'),\n",
       "   (u'dad', u'mom', u'husband', u'wife'),\n",
       "   (u'dad', u'mom', u'stepfather', u'stepmother')],\n",
       "  'section': u'family'},\n",
       " {'correct': [(u'boy', u'girl', u'brother', u'sister'),\n",
       "   (u'boy', u'girl', u'brothers', u'sisters'),\n",
       "   (u'boy', u'girl', u'dad', u'mom'),\n",
       "   (u'boy', u'girl', u'father', u'mother'),\n",
       "   (u'boy', u'girl', u'grandfather', u'grandmother'),\n",
       "   (u'boy', u'girl', u'grandson', u'granddaughter'),\n",
       "   (u'boy', u'girl', u'groom', u'bride'),\n",
       "   (u'boy', u'girl', u'he', u'she'),\n",
       "   (u'boy', u'girl', u'his', u'her'),\n",
       "   (u'boy', u'girl', u'husband', u'wife'),\n",
       "   (u'boy', u'girl', u'king', u'queen'),\n",
       "   (u'boy', u'girl', u'man', u'woman'),\n",
       "   (u'boy', u'girl', u'nephew', u'niece'),\n",
       "   (u'boy', u'girl', u'prince', u'princess'),\n",
       "   (u'boy', u'girl', u'son', u'daughter'),\n",
       "   (u'boy', u'girl', u'sons', u'daughters'),\n",
       "   (u'boy', u'girl', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'brothers', u'sisters'),\n",
       "   (u'brother', u'sister', u'dad', u'mom'),\n",
       "   (u'brother', u'sister', u'father', u'mother'),\n",
       "   (u'brother', u'sister', u'grandfather', u'grandmother'),\n",
       "   (u'brother', u'sister', u'grandson', u'granddaughter'),\n",
       "   (u'brother', u'sister', u'groom', u'bride'),\n",
       "   (u'brother', u'sister', u'he', u'she'),\n",
       "   (u'brother', u'sister', u'his', u'her'),\n",
       "   (u'brother', u'sister', u'husband', u'wife'),\n",
       "   (u'brother', u'sister', u'king', u'queen'),\n",
       "   (u'brother', u'sister', u'man', u'woman'),\n",
       "   (u'brother', u'sister', u'nephew', u'niece'),\n",
       "   (u'brother', u'sister', u'prince', u'princess'),\n",
       "   (u'brother', u'sister', u'son', u'daughter'),\n",
       "   (u'brother', u'sister', u'sons', u'daughters'),\n",
       "   (u'brother', u'sister', u'uncle', u'aunt'),\n",
       "   (u'brother', u'sister', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'dad', u'mom'),\n",
       "   (u'brothers', u'sisters', u'father', u'mother'),\n",
       "   (u'brothers', u'sisters', u'grandfather', u'grandmother'),\n",
       "   (u'brothers', u'sisters', u'grandson', u'granddaughter'),\n",
       "   (u'brothers', u'sisters', u'groom', u'bride'),\n",
       "   (u'brothers', u'sisters', u'he', u'she'),\n",
       "   (u'brothers', u'sisters', u'his', u'her'),\n",
       "   (u'brothers', u'sisters', u'husband', u'wife'),\n",
       "   (u'brothers', u'sisters', u'king', u'queen'),\n",
       "   (u'brothers', u'sisters', u'man', u'woman'),\n",
       "   (u'brothers', u'sisters', u'nephew', u'niece'),\n",
       "   (u'brothers', u'sisters', u'prince', u'princess'),\n",
       "   (u'brothers', u'sisters', u'son', u'daughter'),\n",
       "   (u'brothers', u'sisters', u'sons', u'daughters'),\n",
       "   (u'brothers', u'sisters', u'uncle', u'aunt'),\n",
       "   (u'brothers', u'sisters', u'boy', u'girl'),\n",
       "   (u'brothers', u'sisters', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'father', u'mother'),\n",
       "   (u'dad', u'mom', u'grandfather', u'grandmother'),\n",
       "   (u'dad', u'mom', u'grandson', u'granddaughter'),\n",
       "   (u'dad', u'mom', u'groom', u'bride'),\n",
       "   (u'dad', u'mom', u'he', u'she'),\n",
       "   (u'dad', u'mom', u'his', u'her'),\n",
       "   (u'dad', u'mom', u'king', u'queen'),\n",
       "   (u'dad', u'mom', u'man', u'woman'),\n",
       "   (u'dad', u'mom', u'nephew', u'niece'),\n",
       "   (u'dad', u'mom', u'prince', u'princess'),\n",
       "   (u'dad', u'mom', u'son', u'daughter'),\n",
       "   (u'dad', u'mom', u'sons', u'daughters'),\n",
       "   (u'dad', u'mom', u'uncle', u'aunt'),\n",
       "   (u'dad', u'mom', u'boy', u'girl'),\n",
       "   (u'dad', u'mom', u'brother', u'sister'),\n",
       "   (u'dad', u'mom', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'grandfather', u'grandmother'),\n",
       "   (u'father', u'mother', u'grandson', u'granddaughter'),\n",
       "   (u'father', u'mother', u'groom', u'bride'),\n",
       "   (u'father', u'mother', u'he', u'she'),\n",
       "   (u'father', u'mother', u'his', u'her'),\n",
       "   (u'father', u'mother', u'husband', u'wife'),\n",
       "   (u'father', u'mother', u'king', u'queen'),\n",
       "   (u'father', u'mother', u'man', u'woman'),\n",
       "   (u'father', u'mother', u'nephew', u'niece'),\n",
       "   (u'father', u'mother', u'prince', u'princess'),\n",
       "   (u'father', u'mother', u'son', u'daughter'),\n",
       "   (u'father', u'mother', u'sons', u'daughters'),\n",
       "   (u'father', u'mother', u'stepfather', u'stepmother'),\n",
       "   (u'father', u'mother', u'uncle', u'aunt'),\n",
       "   (u'father', u'mother', u'boy', u'girl'),\n",
       "   (u'father', u'mother', u'brother', u'sister'),\n",
       "   (u'father', u'mother', u'brothers', u'sisters'),\n",
       "   (u'father', u'mother', u'dad', u'mom')],\n",
       "  'incorrect': [(u'boy', u'girl', u'stepfather', u'stepmother'),\n",
       "   (u'brother', u'sister', u'stepfather', u'stepmother'),\n",
       "   (u'brothers', u'sisters', u'stepfather', u'stepmother'),\n",
       "   (u'dad', u'mom', u'husband', u'wife'),\n",
       "   (u'dad', u'mom', u'stepfather', u'stepmother')],\n",
       "  'section': 'total'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gensim supports the same evaluation set as Google does\n",
    "w2v_model.accuracy('data/questions-words-test.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
